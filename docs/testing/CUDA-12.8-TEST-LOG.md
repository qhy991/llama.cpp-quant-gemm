# CUDA 12.8 环境测试日志

**测试日期**: 2026-01-29
**测试环境**: conda activate KM-12.8

---

## 1. 环境验证

### 1.1 CUDA 版本检查

```bash
$ source ~/miniconda3/etc/profile.d/conda.sh && conda activate KM-12.8
$ which nvcc && nvcc --version
```

**输出:**
```
/home/haiyan/miniconda3/envs/KM-12.8/bin/nvcc
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2025 NVIDIA Corporation
Built on Fri_Feb_21_20:23:50_PST_2025
Cuda compilation tools, release 12.8, V12.8.93
Build cuda_12.8.r12.8/compiler.35583870_0
```

---

## 2. 编译过程记录

### 2.1 CMake 配置

```bash
$ cd /home/haiyan/Agent4Kernel/llama.cpp
$ rm -rf build && mkdir build && cd build
$ cmake .. -DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES="120" -DLLAMA_BUILD_TESTS=ON
```

**关键输出:**
```
-- Found CUDAToolkit: /home/haiyan/miniconda3/envs/KM-12.8/targets/x86_64-linux/include (found version "12.8.93")
-- CUDA Toolkit found
-- The CUDA compiler identification is NVIDIA 12.8.93 with host compiler GNU 14.3.0
-- Replacing 120 in CMAKE_CUDA_ARCHITECTURES with 120a
-- Replacing 120-real in CMAKE_CUDA_ARCHITECTURES_NATIVE with 120a-real
-- Using CMAKE_CUDA_ARCHITECTURES=120a CMAKE_CUDA_ARCHITECTURES_NATIVE=120a-real
-- CUDA host compiler is GNU 14.3.0
-- Including CUDA backend
-- ggml version: 0.9.5
-- ggml commit:  0c21677e4-dirty
-- Found OpenSSL: /home/haiyan/miniconda3/envs/KM-12.8/lib/libcrypto.so (found version "3.6.0")
-- Configuring done (39.3s)
-- Generating done (0.3s)
-- Build files have been written to: /home/haiyan/Agent4Kernel/llama.cpp/build
```

### 2.2 编译 test-backend-ops

```bash
$ cmake --build . --target test-backend-ops -j$(nproc)
```

**输出 (最后几行):**
```
[100%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o
[100%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o
[100%] Linking CXX executable ../bin/test-backend-ops
[100%] Built target test-backend-ops
```

---

## 3. test-backend-ops 测试输出

### 3.1 Q4_0 测试

```bash
$ ./test-backend-ops perf -o MUL_MAT -b CUDA0 -p "type_a=q4_0"
```

**完整输出:**
```
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 5070 Laptop GPU, compute capability 12.0, VMM: yes
Testing 2 devices

Backend 1/2: CUDA0
  Device description: NVIDIA GeForce RTX 5070 Laptop GPU
  Device memory: 8150 MB (6999 MB free)

  MUL_MAT(type_a=q4_0,type_b=f32,m=4096,n=1,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 3408 runs -   331.68 us/run - 117.44 MFLOP/run - 354.08 GFLOPS
  MUL_MAT(type_a=q4_0,type_b=f32,m=4096,n=2,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 3408 runs -   302.97 us/run - 234.88 MFLOP/run - 775.26 GFLOPS
  MUL_MAT(type_a=q4_0,type_b=f32,m=4096,n=3,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 3124 runs -   322.02 us/run - 352.32 MFLOP/run -   1.09 TFLOPS
  MUL_MAT(type_a=q4_0,type_b=f32,m=4096,n=4,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 2982 runs -   349.50 us/run - 469.76 MFLOP/run -   1.34 TFLOPS
  MUL_MAT(type_a=q4_0,type_b=f32,m=4096,n=5,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 2394 runs -   434.94 us/run - 587.20 MFLOP/run -   1.35 TFLOPS
  MUL_MAT(type_a=q4_0,type_b=f32,m=4096,n=8,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1): CUDA error: an illegal memory access was encountered
  current device: 0, in function ggml_backend_cuda_synchronize at /home/haiyan/Agent4Kernel/llama.cpp/ggml/src/ggml-cuda/ggml-cuda.cu:2850
  cudaStreamSynchronize(cuda_ctx->stream())
```

> ⚠️ **注意**: Q4_0 在 N=8 时触发 CUDA 内存访问错误，这是 sm_120 (Blackwell) 架构的兼容性问题。

### 3.2 Q8_0 测试

```bash
$ ./test-backend-ops perf -o MUL_MAT -b CUDA0 -p "type_a=q8_0"
```

**完整输出:**
```
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 5070 Laptop GPU, compute capability 12.0, VMM: yes
Testing 2 devices

Backend 1/2: CUDA0
  Device description: NVIDIA GeForce RTX 5070 Laptop GPU
  Device memory: 8150 MB (6999 MB free)

  MUL_MAT(type_a=q8_0,type_b=f32,m=4096,n=1,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 1704 runs -   776.24 us/run - 117.44 MFLOP/run - 151.29 GFLOPS
  MUL_MAT(type_a=q8_0,type_b=f32,m=4096,n=2,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 1278 runs -   793.24 us/run - 234.88 MFLOP/run - 296.10 GFLOPS
  MUL_MAT(type_a=q8_0,type_b=f32,m=4096,n=3,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 1420 runs -   831.83 us/run - 352.32 MFLOP/run - 423.55 GFLOPS
  MUL_MAT(type_a=q8_0,type_b=f32,m=4096,n=4,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 1278 runs -   806.36 us/run - 469.76 MFLOP/run - 582.57 GFLOPS
  MUL_MAT(type_a=q8_0,type_b=f32,m=4096,n=5,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 1368 runs -   828.07 us/run - 587.20 MFLOP/run - 709.12 GFLOPS
  MUL_MAT(type_a=q8_0,type_b=f32,m=4096,n=8,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                 1070 runs -  1027.74 us/run - 939.52 MFLOP/run - 914.16 GFLOPS
  MUL_MAT(type_a=q8_0,type_b=f32,m=4096,n=512,k=14336,bs=[1,1],nr=[1,1],per=[0,1,2,3],k_v=0,o=1):                148 runs -  6813.41 us/run -  60.13 GFLOP/run -   8.83 TFLOPS
  Backend CUDA0: OK
Backend 2/2: CPU
  Skipping
2/2 backends passed
OK
```

---

## 4. Naive Kernel 测试输出

### 4.1 test-quantized-gemm-cuda

```bash
$ cd /home/haiyan/Agent4Kernel/llama.cpp/tests
$ ./test-quantized-gemm-cuda
```

**输出:**
```
╔════════════════════════════════════════════════════════════════════════════════════════╗
║              llama.cpp 量化 GEMM CUDA 性能测试                                         ║
║              对应 kerneleval baselines: w4a16, w8a16, w4a8, w8a8                       ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║  GPU: NVIDIA GeForce RTX 5070 Laptop GPU                                           ║
║  Compute Capability: sm_120                                                           ║
║  SMs: 36, Memory: 8.5 GB                                                              ║
╚════════════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════════════╗
║  W4A16 (Q4_0) - Naive CUDA Kernel (对应 kerneleval w4a16/group32)                      ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║ Config              │ Kernel           │ Dimensions            │ Time(ms) │ TFLOPS    ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║ M1_K4096_N4096      │ W4A16 (Q4_0)     │    1 x  4096 x  4096 │   0.1829 │      0.18 ║
║ M7_K4096_N4096      │ W4A16 (Q4_0)     │    7 x  4096 x  4096 │   1.6521 │      0.14 ║
║ M32_K4096_N4096     │ W4A16 (Q4_0)     │   32 x  4096 x  4096 │   6.2333 │      0.17 ║
║ M128_K4096_N4096    │ W4A16 (Q4_0)     │  128 x  4096 x  4096 │  28.6871 │      0.15 ║
║ M256_K4096_N4096    │ W4A16 (Q4_0)     │  256 x  4096 x  4096 │  63.9190 │      0.13 ║
║ M512_K4096_N4096    │ W4A16 (Q4_0)     │  512 x  4096 x  4096 │ 118.6709 │      0.14 ║
║ M1024_K4096_N4096   │ W4A16 (Q4_0)     │ 1024 x  4096 x  4096 │ 238.4961 │      0.14 ║
║ M128_K4096_N11008   │ W4A16 (Q4_0)     │  128 x  4096 x 11008 │  82.5161 │      0.14 ║
║ M128_K11008_N4096   │ W4A16 (Q4_0)     │  128 x 11008 x  4096 │  44.5684 │      0.26 ║
╚════════════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════════════╗
║  W8A16 (Q8_0) - Naive CUDA Kernel (对应 kerneleval w8a16/group32)                      ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║ Config              │ Kernel           │ Dimensions            │ Time(ms) │ TFLOPS    ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║ M1_K4096_N4096      │ W8A16 (Q8_0)     │    1 x  4096 x  4096 │   0.3941 │      0.09 ║
║ M7_K4096_N4096      │ W8A16 (Q8_0)     │    7 x  4096 x  4096 │   4.6540 │      0.05 ║
║ M32_K4096_N4096     │ W8A16 (Q8_0)     │   32 x  4096 x  4096 │  14.9165 │      0.07 ║
║ M128_K4096_N4096    │ W8A16 (Q8_0)     │  128 x  4096 x  4096 │  56.4697 │      0.08 ║
║ M256_K4096_N4096    │ W8A16 (Q8_0)     │  256 x  4096 x  4096 │ 107.3017 │      0.08 ║
║ M512_K4096_N4096    │ W8A16 (Q8_0)     │  512 x  4096 x  4096 │ 205.0134 │      0.08 ║
║ M1024_K4096_N4096   │ W8A16 (Q8_0)     │ 1024 x  4096 x  4096 │ 419.7596 │      0.08 ║
║ M128_K4096_N11008   │ W8A16 (Q8_0)     │  128 x  4096 x 11008 │ 138.1596 │      0.08 ║
║ M128_K11008_N4096   │ W8A16 (Q8_0)     │  128 x 11008 x  4096 │  69.3844 │      0.17 ║
╚════════════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════════════╗
║  W4A8 (Q4_0+Q8_1) - Naive CUDA Kernel (对应 kerneleval w4a8)                           ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║ Config              │ Kernel           │ Dimensions            │ Time(ms) │ TFLOPS    ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║ M1_K4096_N4096      │ W4A8 (Q4_0+Q8_1) │    1 x  4096 x  4096 │   0.1905 │      0.18 ║
║ M7_K4096_N4096      │ W4A8 (Q4_0+Q8_1) │    7 x  4096 x  4096 │   1.6119 │      0.15 ║
║ M32_K4096_N4096     │ W4A8 (Q4_0+Q8_1) │   32 x  4096 x  4096 │   7.2851 │      0.15 ║
║ M128_K4096_N4096    │ W4A8 (Q4_0+Q8_1) │  128 x  4096 x  4096 │  28.6325 │      0.15 ║
║ M256_K4096_N4096    │ W4A8 (Q4_0+Q8_1) │  256 x  4096 x  4096 │  58.2244 │      0.15 ║
║ M512_K4096_N4096    │ W4A8 (Q4_0+Q8_1) │  512 x  4096 x  4096 │ 118.7879 │      0.14 ║
║ M1024_K4096_N4096   │ W4A8 (Q4_0+Q8_1) │ 1024 x  4096 x  4096 │ 234.4207 │      0.15 ║
║ M128_K4096_N11008   │ W4A8 (Q4_0+Q8_1) │  128 x  4096 x 11008 │  79.5076 │      0.15 ║
║ M128_K11008_N4096   │ W4A8 (Q4_0+Q8_1) │  128 x 11008 x  4096 │  40.3439 │      0.29 ║
╚════════════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════════════╗
║  W8A8 (Q8_0+Q8_1) - Naive CUDA Kernel (对应 kerneleval w8a8)                           ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║ Config              │ Kernel           │ Dimensions            │ Time(ms) │ TFLOPS    ║
╠════════════════════════════════════════════════════════════════════════════════════════╣
║ M1_K4096_N4096      │ W8A8 (Q8_0+Q8_1) │    1 x  4096 x  4096 │   0.3300 │      0.10 ║
║ M7_K4096_N4096      │ W8A8 (Q8_0+Q8_1) │    7 x  4096 x  4096 │   4.3551 │      0.05 ║
║ M32_K4096_N4096     │ W8A8 (Q8_0+Q8_1) │   32 x  4096 x  4096 │  12.0294 │      0.09 ║
║ M128_K4096_N4096    │ W8A8 (Q8_0+Q8_1) │  128 x  4096 x  4096 │  55.4798 │      0.08 ║
║ M256_K4096_N4096    │ W8A8 (Q8_0+Q8_1) │  256 x  4096 x  4096 │ 102.6695 │      0.08 ║
║ M512_K4096_N4096    │ W8A8 (Q8_0+Q8_1) │  512 x  4096 x  4096 │ 206.2452 │      0.08 ║
║ M1024_K4096_N4096   │ W8A8 (Q8_0+Q8_1) │ 1024 x  4096 x  4096 │ 411.9336 │      0.08 ║
║ M128_K4096_N11008   │ W8A8 (Q8_0+Q8_1) │  128 x  4096 x 11008 │ 138.5657 │      0.08 ║
║ M128_K11008_N4096   │ W8A8 (Q8_0+Q8_1) │  128 x 11008 x  4096 │  69.4454 │      0.17 ║
╚════════════════════════════════════════════════════════════════════════════════════════╝
```

### 4.2 test-naive-vs-optimized

```bash
$ ./test-naive-vs-optimized
```

**输出:**
```
╔══════════════════════════════════════════════════════════════════════════════════╗
║              Naive vs Optimized GEMM Kernel Comparison                           ║
╠══════════════════════════════════════════════════════════════════════════════════╣
║  GPU: NVIDIA GeForce RTX 5070 Laptop GPU                                         ║
║  SM: 36, Compute: sm_120, Memory: 8.5 GB                                        ║
╠══════════════════════════════════════════════════════════════════════════════════╣
║                                                                                  ║
║  测试不同优化级别的 W4A16 GEMM kernel                                             ║
║  1. Naive: 每线程计算一个输出元素                                                 ║
║  2. Tiled: 使用共享内存 tiling                                                    ║
║  3. Vectorized: 使用 float4 向量化加载                                            ║
║                                                                                  ║
║  注意: llama.cpp 的优化 kernel 还使用了 DP4A/Tensor Core,                         ║
║        性能会比这里的优化版本高 5-10x                                              ║
╚══════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════╗
║  Matrix Size: M=1, K=4096, N=4096                                            ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Kernel                    │   Time(ms) │       TFLOPS │   Max Diff │  Speedup ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Naive (16x16 block)       │     0.2059 │        0.163 │   0.00e+00 │    1.00x ║
║ Tiled (shared mem)        │     1.6750 │        0.020 │   4.77e-05 │    0.12x ║
║ Vectorized (float4)       │     0.1847 │        0.182 │   3.81e-05 │    1.11x ║
╚════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════╗
║  Matrix Size: M=32, K=4096, N=4096                                            ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Kernel                    │   Time(ms) │       TFLOPS │   Max Diff │  Speedup ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Naive (16x16 block)       │     6.2444 │        0.172 │   0.00e+00 │    1.00x ║
║ Tiled (shared mem)        │     3.3149 │        0.324 │   8.39e-05 │    1.88x ║
║ Vectorized (float4)       │     6.0397 │        0.178 │   6.29e-05 │    1.03x ║
╚════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════╗
║  Matrix Size: M=128, K=4096, N=4096                                            ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Kernel                    │   Time(ms) │       TFLOPS │   Max Diff │  Speedup ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Naive (16x16 block)       │    30.9650 │        0.139 │   0.00e+00 │    1.00x ║
║ Tiled (shared mem)        │    18.0541 │        0.238 │   9.16e-05 │    1.72x ║
║ Vectorized (float4)       │    26.5001 │        0.162 │   6.87e-05 │    1.17x ║
╚════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════╗
║  Matrix Size: M=512, K=4096, N=4096                                            ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Kernel                    │   Time(ms) │       TFLOPS │   Max Diff │  Speedup ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Naive (16x16 block)       │   116.0769 │        0.148 │   0.00e+00 │    1.00x ║
║ Tiled (shared mem)        │    67.1659 │        0.256 │   1.22e-04 │    1.73x ║
║ Vectorized (float4)       │   107.2124 │        0.160 │   7.63e-05 │    1.08x ║
╚════════════════════════════════════════════════════════════════════════════════╝

╔════════════════════════════════════════════════════════════════════════════════╗
║  Matrix Size: M=512, K=14336, N=4096                                            ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Kernel                    │   Time(ms) │       TFLOPS │   Max Diff │  Speedup ║
╠════════════════════════════════════════════════════════════════════════════════╣
║ Naive (16x16 block)       │   420.1246 │        0.143 │   0.00e+00 │    1.00x ║
║ Tiled (shared mem)        │   239.5722 │        0.251 │   2.98e-04 │    1.75x ║
║ Vectorized (float4)       │   370.8532 │        0.162 │   2.59e-04 │    1.13x ║
╚════════════════════════════════════════════════════════════════════════════════╝
```

### 4.3 llama_cpp_comparison_test

```bash
$ ./llama_cpp_comparison_test
```

**输出:**
```
╔══════════════════════════════════════════════════════════════════╗
║   与 llama.cpp 算子对比测试                               ║
║   Baseline Per-channel vs llama.cpp Q8_0                  ║
╚══════════════════════════════════════════════════════════════════╝

GPU: NVIDIA GeForce RTX 5070 Laptop GPU
Compute Capability: 12.0
SM Count: 36

═════════════════════════════════════════════════════════
测试配置:
  - Baseline: Per-channel INT8 权重 (kerneleval 风格)
  - Q8_0: llama.cpp block 格式 (每 32 元素一个 scale)
  - Warmup: 5 iterations
  - Test: 20 iterations (取中位数)
═════════════════════════════════════════════════════════

╔═════════════════════════════════════════════════════════╗
║  测试: M1_K4096_N4096 (M=1, K=4096, N=4096)
╠═════════════════════════════════════════════════════════╣
║  格式              量化(ms)  GEMM(ms)  总时间(ms)  TFLOPS  内存(MB)
║  ─────────────────────────────────────────────────────────
║  Baseline-PerCh        1.1988    1.2956     2.4944      0.01        16 MB
║  llama-Q8_0            1.2003    1.3553     2.5556      0.01        17 MB
║  ─────────────────────────────────────────────────────────
║  对比:
║    加速比: Q8_0 vs Baseline = 1.02x
║    内存: Q8_0 / Baseline = 1.06x (6.1% 增加)
║    TFLOPS 差异: -2.40%
╚═════════════════════════════════════════════════════════╝

╔═════════════════════════════════════════════════════════╗
║  测试: M128_K4096_N4096 (M=128, K=4096, N=4096)
╠═════════════════════════════════════════════════════════╣
║  格式              量化(ms)  GEMM(ms)  总时间(ms)  TFLOPS  内存(MB)
║  ─────────────────────────────────────────────────────────
║  Baseline-PerCh        3.9396   33.9064    37.8459      0.11        16 MB
║  llama-Q8_0            4.4094   37.6549    42.0643      0.10        17 MB
║  ─────────────────────────────────────────────────────────
║  对比:
║    加速比: Q8_0 vs Baseline = 1.11x
║    内存: Q8_0 / Baseline = 1.06x (6.1% 增加)
║    TFLOPS 差异: -10.03%
╚═════════════════════════════════════════════════════════╝

╔═════════════════════════════════════════════════════════╗
║  测试: M256_K4096_N4096 (M=256, K=4096, N=4096)
╠═════════════════════════════════════════════════════════╣
║  格式              量化(ms)  GEMM(ms)  总时间(ms)  TFLOPS  内存(MB)
║  ─────────────────────────────────────────────────────────
║  Baseline-PerCh        7.3646   72.3638    79.7284      0.11        16 MB
║  llama-Q8_0            6.8172   73.7096    80.5268      0.11        17 MB
║  ─────────────────────────────────────────────────────────
║  对比:
║    加速比: Q8_0 vs Baseline = 1.01x
║    内存: Q8_0 / Baseline = 1.06x (6.1% 增加)
║    TFLOPS 差异: -0.99%
╚═════════════════════════════════════════════════════════╝

═════════════════════════════════════════════════════════
关键发现:
  1. Baseline (Per-channel): 每列一个 scale
  2. llama.cpp Q8_0: 每 32 元素一个 scale (Block)
  3. Block 格式提供更精细的量化，可能提高精度
  4. Per-channel 格式内存效率更高

数据格式对比:
  Baseline:  INT8[N*K] + float[N]
  Q8_0:      {half d + int8[32]}[N*K/32]
═════════════════════════════════════════════════════════
```

---

## 5. 性能总结

### 5.1 llama.cpp 官方 kernel 性能

| 量化类型 | 矩阵配置 | 时间 | TFLOPS |
|---------|---------|------|--------|
| Q4_0 | M=4096, N=1, K=14336 | 331.68 us | 0.35 |
| Q4_0 | M=4096, N=4, K=14336 | 349.50 us | 1.34 |
| Q4_0 | M=4096, N=5, K=14336 | 434.94 us | 1.35 |
| Q8_0 | M=4096, N=1, K=14336 | 776.24 us | 0.15 |
| Q8_0 | M=4096, N=8, K=14336 | 1027.74 us | 0.91 |
| **Q8_0** | **M=4096, N=512, K=14336** | **6813.41 us** | **8.83** |

### 5.2 Naive kernel 性能

| 量化类型 | 矩阵配置 | 时间 | TFLOPS |
|---------|---------|------|--------|
| W4A16 (Q4_0) | M=128, K=4096, N=4096 | 28.69 ms | 0.15 |
| W8A16 (Q8_0) | M=128, K=4096, N=4096 | 56.47 ms | 0.08 |
| W4A8 | M=128, K=4096, N=4096 | 28.63 ms | 0.15 |
| W8A8 | M=128, K=4096, N=4096 | 55.48 ms | 0.08 |

### 5.3 优化对比

| Kernel 类型 | 典型性能 | 相对 Naive |
|-------------|---------|-----------|
| Naive | 0.08-0.15 TFLOPS | 1x |
| Tiled (shared mem) | 0.24-0.32 TFLOPS | ~2x |
| llama.cpp 优化 | 8.83 TFLOPS | **~110x** |

---

## 6. 已知问题

1. **Q4_0 在 sm_120 上的兼容性问题**
   - 症状: N≥8 时出现 "illegal memory access" 错误
   - 原因: llama.cpp 的 Q4_0 kernel 可能尚未完全适配 Blackwell 架构
   - 解决: 等待 llama.cpp 更新，或使用 Q8_0

2. **cutlass 未安装**
   - CMake 警告 "cutlass not found"
   - 影响: 部分高级优化功能不可用
   - 解决: 安装 NVIDIA CUTLASS 库（可选）
