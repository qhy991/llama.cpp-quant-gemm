# ğŸ¯ CUDA Kernel å­¦ä¹ å·¥ç¨‹æ¶æ„è®¾è®¡

**é¡¹ç›®åç§°**: quant-gemm-from-scratch
**ç›®æ ‡**: æ‰‹åŠ¨å®ç° llama.cpp ä¸­çš„ CUDA ç®—å­ï¼Œç”¨äºå­¦ä¹ å’Œæ›¿æ¢

---

## ğŸ“‹ ç›®å½•

1. [è®¾è®¡ç†å¿µ](#1-è®¾è®¡ç†å¿µ)
2. [å·¥ç¨‹ç»“æ„](#2-å·¥ç¨‹ç»“æ„)
3. [æ ¸å¿ƒæ¨¡å—è®¾è®¡](#3-æ ¸å¿ƒæ¨¡å—è®¾è®¡)
4. [ä¸ llama.cpp çš„å…¼å®¹æ€§](#4-ä¸-llamacpp-çš„å…¼å®¹æ€§)
5. [æµ‹è¯•ç­–ç•¥](#5-æµ‹è¯•ç­–ç•¥)
6. [æ•™ç¨‹åšå®¢ç³»ç»Ÿ](#6-æ•™ç¨‹åšå®¢ç³»ç»Ÿ)
7. [å¼€å‘æµç¨‹](#7-å¼€å‘æµç¨‹)
8. [ç®—å­å®ç°è·¯çº¿å›¾](#8-ç®—å­å®ç°è·¯çº¿å›¾)

---

## 1. è®¾è®¡ç†å¿µ

### 1.1 æ ¸å¿ƒåŸåˆ™

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      è®¾è®¡åŸåˆ™                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. ç‹¬ç«‹æ€§ï¼šä¸ä¾èµ– llama.cpp æºç å³å¯ç¼–è¯‘å’Œæµ‹è¯•                  â”‚
â”‚  2. å…¼å®¹æ€§ï¼šä½¿ç”¨ä¸ llama.cpp å®Œå…¨ç›¸åŒçš„æ¥å£å®šä¹‰                  â”‚
â”‚  3. å¯æ›¿æ¢ï¼šå¯ä»¥ç›´æ¥æ›¿æ¢ llama.cpp ä¸­çš„å¯¹åº”ç®—å­                  â”‚
â”‚  4. å¯å­¦ä¹ ï¼šä»£ç æ¸…æ™°ï¼Œæœ‰è¯¦ç»†æ³¨é‡Šå’Œé…å¥—æ•™ç¨‹                       â”‚
â”‚  5. æ¸è¿›å¼ï¼šä»ç®€å•åˆ°å¤æ‚ï¼Œå¾ªåºæ¸è¿›                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ç‹¬ç«‹ä½†å…¼å®¹çš„ç­–ç•¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  quant-gemm-from-    â”‚      â”‚      llama.cpp       â”‚
â”‚      scratch         â”‚      â”‚                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      â”‚      â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚compat/         â”‚â—„â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”‚ggml/src/       â”‚  â”‚
â”‚  â”‚ ggml_types.h   â”‚  â”‚ å¤åˆ¶ â”‚  â”‚ggml-common.h   â”‚  â”‚
â”‚  â”‚ (ç±»å‹å®šä¹‰)     â”‚  â”‚      â”‚  â”‚                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚           â”‚      â”‚          â”‚           â”‚
â”‚          â–¼           â”‚      â”‚          â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚kernels/        â”‚  â”‚ ç›¸åŒ â”‚  â”‚ggml-cuda/      â”‚  â”‚
â”‚  â”‚ gemm.cuh       â”‚â—„â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”‚ mmq.cuh        â”‚  â”‚
â”‚  â”‚ (ç®—å­å®ç°)     â”‚  â”‚ æ¥å£ â”‚  â”‚                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚           â”‚      â”‚          â”‚           â”‚
â”‚          â–¼           â”‚      â”‚          â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚tests/          â”‚  â”‚      â”‚  â”‚tests/          â”‚  â”‚
â”‚  â”‚ (ç‹¬ç«‹æµ‹è¯•)     â”‚  â”‚      â”‚  â”‚test-backend-opsâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚      â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. å·¥ç¨‹ç»“æ„

### 2.1 æ¨èçš„ç›®å½•ç»“æ„

```
quant-gemm-from-scratch/
â”‚
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ CMakeLists.txt               # æ„å»ºé…ç½®
â”œâ”€â”€ Makefile                     # ç®€æ˜“æ„å»º
â”‚
â”œâ”€â”€ compat/                      # ğŸ”§ å…¼å®¹å±‚ï¼ˆä¸ llama.cpp ç±»å‹å…¼å®¹ï¼‰
â”‚   â”œâ”€â”€ README.md                # å…¼å®¹å±‚è¯´æ˜
â”‚   â”œâ”€â”€ ggml_types.h             # ä» llama.cpp æå–çš„ç±»å‹å®šä¹‰
â”‚   â”œâ”€â”€ ggml_quant.h             # é‡åŒ–ç›¸å…³ç±»å‹å’Œå¸¸é‡
â”‚   â””â”€â”€ cuda_compat.h            # CUDA å…¼å®¹æ€§å®
â”‚
â”œâ”€â”€ include/                     # ğŸ“¦ å…¬å…±å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ config.h                 # å…¨å±€é…ç½®
â”‚   â”œâ”€â”€ error.h                  # é”™è¯¯å¤„ç†
â”‚   â””â”€â”€ utils.h                  # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ kernels/                     # ğŸš€ ç®—å­å®ç°ï¼ˆæ ¸å¿ƒï¼‰
â”‚   â”œâ”€â”€ README.md                # ç®—å­å¼€å‘æŒ‡å—
â”‚   â”‚
â”‚   â”œâ”€â”€ gemm/                    # çŸ©é˜µä¹˜æ³•ç®—å­
â”‚   â”‚   â”œâ”€â”€ gemm_naive.cuh       # Level 0: æœ´ç´ å®ç°
â”‚   â”‚   â”œâ”€â”€ gemm_tiled.cuh       # Level 1: Tiled ä¼˜åŒ–
â”‚   â”‚   â”œâ”€â”€ gemm_q4_0.cuh        # Level 2: Q4_0 é‡åŒ–
â”‚   â”‚   â”œâ”€â”€ gemm_q8_0.cuh        # Level 3: Q8_0 é‡åŒ–
â”‚   â”‚   â”œâ”€â”€ gemm_dp4a.cuh        # Level 4: DP4A ä¼˜åŒ–
â”‚   â”‚   â””â”€â”€ README.md            # GEMM å®ç°æ•™ç¨‹
â”‚   â”‚
â”‚   â”œâ”€â”€ elementwise/             # å…ƒç´ çº§ç®—å­
â”‚   â”‚   â”œâ”€â”€ add.cuh              # åŠ æ³•
â”‚   â”‚   â”œâ”€â”€ mul.cuh              # ä¹˜æ³•
â”‚   â”‚   â”œâ”€â”€ scale.cuh            # ç¼©æ”¾
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ activation/              # æ¿€æ´»å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ silu.cuh             # SiLU
â”‚   â”‚   â”œâ”€â”€ gelu.cuh             # GELU
â”‚   â”‚   â”œâ”€â”€ relu.cuh             # ReLU
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ normalization/           # å½’ä¸€åŒ–ç®—å­
â”‚   â”‚   â”œâ”€â”€ rms_norm.cuh         # RMS Norm
â”‚   â”‚   â”œâ”€â”€ layer_norm.cuh       # Layer Norm
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ attention/               # æ³¨æ„åŠ›ç›¸å…³
â”‚   â”‚   â”œâ”€â”€ softmax.cuh          # Softmax
â”‚   â”‚   â”œâ”€â”€ rope.cuh             # RoPE
â”‚   â”‚   â”œâ”€â”€ flash_attention.cuh  # Flash Attention
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ quantization/            # é‡åŒ–/åé‡åŒ–
â”‚       â”œâ”€â”€ quantize_q4_0.cuh    # Q4_0 é‡åŒ–
â”‚       â”œâ”€â”€ quantize_q8_0.cuh    # Q8_0 é‡åŒ–
â”‚       â”œâ”€â”€ dequantize.cuh       # åé‡åŒ–
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ tests/                       # ğŸ§ª æµ‹è¯•ç¨‹åº
â”‚   â”œâ”€â”€ framework/               # æµ‹è¯•æ¡†æ¶
â”‚   â”‚   â”œâ”€â”€ test_framework.cuh   # é€šç”¨æµ‹è¯•æ¡†æ¶
â”‚   â”‚   â”œâ”€â”€ data_generator.cuh   # æ•°æ®ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ error_metrics.cuh    # è¯¯å·®åº¦é‡
â”‚   â”‚
â”‚   â”œâ”€â”€ unit/                    # å•å…ƒæµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ test_gemm.cu
â”‚   â”‚   â”œâ”€â”€ test_activation.cu
â”‚   â”‚   â”œâ”€â”€ test_normalization.cu
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/             # é›†æˆæµ‹è¯•ï¼ˆä¸ llama.cppï¼‰
â”‚   â”‚   â”œâ”€â”€ test_llama_compat.cu
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ benchmark/               # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”‚       â”œâ”€â”€ bench_gemm.cu
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ tutorials/                   # ğŸ“š æ•™ç¨‹åšå®¢
â”‚   â”œâ”€â”€ README.md                # æ•™ç¨‹ç´¢å¼•
â”‚   â”‚
â”‚   â”œâ”€â”€ 00-introduction/         # å…¥é—¨ä»‹ç»
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ 01-cuda-basics/          # CUDA åŸºç¡€
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ hello_cuda.cu
â”‚   â”‚   â””â”€â”€ memory_hierarchy.md
â”‚   â”‚
â”‚   â”œâ”€â”€ 02-gemm-from-scratch/    # GEMM ä»é›¶å®ç°
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ step1_naive.md
â”‚   â”‚   â”œâ”€â”€ step2_tiled.md
â”‚   â”‚   â”œâ”€â”€ step3_shared_memory.md
â”‚   â”‚   â””â”€â”€ code/
â”‚   â”‚
â”‚   â”œâ”€â”€ 03-quantization/         # é‡åŒ–æŠ€æœ¯
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ theory.md
â”‚   â”‚   â”œâ”€â”€ q4_0_implementation.md
â”‚   â”‚   â””â”€â”€ code/
â”‚   â”‚
â”‚   â”œâ”€â”€ 04-dp4a-optimization/    # DP4A ä¼˜åŒ–
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ dp4a_intro.md
â”‚   â”‚   â”œâ”€â”€ implementation.md
â”‚   â”‚   â””â”€â”€ code/
â”‚   â”‚
â”‚   â””â”€â”€ 05-llama-integration/    # llama.cpp é›†æˆ
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ interface_analysis.md
â”‚       â”œâ”€â”€ integration_guide.md
â”‚       â””â”€â”€ code/
â”‚
â”œâ”€â”€ tools/                       # ğŸ”¨ å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ sync_llama_types.py      # åŒæ­¥ llama.cpp ç±»å‹å®šä¹‰
â”‚   â”œâ”€â”€ generate_test.py         # ç”Ÿæˆæµ‹è¯•ä»£ç 
â”‚   â””â”€â”€ benchmark.py             # æ€§èƒ½æµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ examples/                    # ğŸ’¡ ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ basic_gemm.cu
â”‚   â”œâ”€â”€ quantized_inference.cu
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ docs/                        # ğŸ“– æ–‡æ¡£
    â”œâ”€â”€ API.md                   # API æ–‡æ¡£
    â”œâ”€â”€ CONTRIBUTING.md          # è´¡çŒ®æŒ‡å—
    â””â”€â”€ CHANGELOG.md             # å˜æ›´æ—¥å¿—
```

---

## 3. æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 3.1 å…¼å®¹å±‚ (compat/)

**ç›®çš„**: å®šä¹‰ä¸ llama.cpp å®Œå…¨å…¼å®¹çš„ç±»å‹ï¼Œä½†ä¸ä¾èµ– llama.cpp æºç 

```cpp
// compat/ggml_types.h
#pragma once

#include <cuda_fp16.h>
#include <cstdint>

// ============================================================================
// é‡åŒ–å—å¤§å°å¸¸é‡ï¼ˆä¸ llama.cpp å®Œå…¨ä¸€è‡´ï¼‰
// ============================================================================
#define QK4_0 32
#define QK4_1 32
#define QK5_0 32
#define QK5_1 32
#define QK8_0 32
#define QK8_1 32

// ============================================================================
// é‡åŒ–å—ç±»å‹å®šä¹‰ï¼ˆä¸ llama.cpp å®Œå…¨ä¸€è‡´ï¼‰
// ============================================================================

// Q4_0: 4-bit é‡åŒ–ï¼Œæ— åç§»
typedef struct {
    half d;                 // ç¼©æ”¾å› å­ (delta)
    uint8_t qs[QK4_0/2];   // é‡åŒ–å€¼ï¼Œæ¯å­—èŠ‚ä¸¤ä¸ª 4-bit å€¼
} block_q4_0;
static_assert(sizeof(block_q4_0) == 18, "block_q4_0 size mismatch");

// Q4_1: 4-bit é‡åŒ–ï¼Œæœ‰åç§»
typedef struct {
    half d;                 // ç¼©æ”¾å› å­
    half m;                 // æœ€å°å€¼ (åç§»)
    uint8_t qs[QK4_1/2];   // é‡åŒ–å€¼
} block_q4_1;
static_assert(sizeof(block_q4_1) == 20, "block_q4_1 size mismatch");

// Q8_0: 8-bit é‡åŒ–
typedef struct {
    half d;                 // ç¼©æ”¾å› å­
    int8_t qs[QK8_0];      // é‡åŒ–å€¼
} block_q8_0;
static_assert(sizeof(block_q8_0) == 34, "block_q8_0 size mismatch");

// Q8_1: 8-bit é‡åŒ–ï¼Œå¸¦æ±‚å’Œï¼ˆç”¨äºæ¿€æ´»ï¼‰
typedef struct {
    half2 ds;               // d (ç¼©æ”¾) å’Œ s (æ±‚å’Œ) æ‰“åŒ…ä¸º half2
    int8_t qs[QK8_1];      // é‡åŒ–å€¼
} block_q8_1;
static_assert(sizeof(block_q8_1) == 36, "block_q8_1 size mismatch");

// ============================================================================
// è¾…åŠ©å®å’Œå‡½æ•°
// ============================================================================

// ç±»å‹æšä¸¾ï¼ˆä¸ llama.cpp çš„ ggml_type å¯¹åº”ï¼‰
enum QuantType {
    QUANT_TYPE_F32 = 0,
    QUANT_TYPE_F16 = 1,
    QUANT_TYPE_Q4_0 = 2,
    QUANT_TYPE_Q4_1 = 3,
    QUANT_TYPE_Q5_0 = 6,
    QUANT_TYPE_Q5_1 = 7,
    QUANT_TYPE_Q8_0 = 8,
    QUANT_TYPE_Q8_1 = 9,
};

// è·å–å—å¤§å°
inline int get_block_size(QuantType type) {
    switch (type) {
        case QUANT_TYPE_Q4_0:
        case QUANT_TYPE_Q4_1:
        case QUANT_TYPE_Q5_0:
        case QUANT_TYPE_Q5_1:
        case QUANT_TYPE_Q8_0:
        case QUANT_TYPE_Q8_1:
            return 32;
        default:
            return 1;
    }
}
```

### 3.2 ç®—å­æ¥å£è§„èŒƒ

**è®¾è®¡åŸåˆ™**: æ¯ä¸ªç®—å­éƒ½æœ‰æ ‡å‡†åŒ–çš„æ¥å£

```cpp
// kernels/gemm/gemm_interface.h
#pragma once

#include "compat/ggml_types.h"

namespace kernels {
namespace gemm {

// ============================================================================
// GEMM æ¥å£è§„èŒƒ
// ============================================================================
// æ‰€æœ‰ GEMM å®ç°å¿…é¡»éµå¾ªæ­¤æ¥å£

/**
 * çŸ©é˜µä¹˜æ³•: C = A Ã— B
 *
 * @param A         æ¿€æ´»çŸ©é˜µ [M, K]ï¼Œå¯ä»¥æ˜¯é‡åŒ–ç±»å‹
 * @param B         æƒé‡çŸ©é˜µ [N, K]ï¼Œå¯ä»¥æ˜¯é‡åŒ–ç±»å‹
 * @param C         è¾“å‡ºçŸ©é˜µ [M, N]ï¼Œé€šå¸¸æ˜¯ float
 * @param M         è¾“å‡ºè¡Œæ•°ï¼ˆbatch sizeï¼‰
 * @param N         è¾“å‡ºåˆ—æ•°ï¼ˆoutput dimensionï¼‰
 * @param K         å†…éƒ¨ç»´åº¦ï¼ˆhidden dimensionï¼‰
 * @param stream    CUDA æµ
 */

// Level 0: FP32 Ã— FP32 â†’ FP32
void gemm_fp32(
    const float* A, const float* B, float* C,
    int M, int N, int K, cudaStream_t stream = 0);

// Level 1: Q4_0 Ã— Q8_1 â†’ FP32 (ä¸ llama.cpp æ¥å£ä¸€è‡´)
void gemm_q4_0_q8_1(
    const block_q8_1* A,    // æ¿€æ´» [M, K/32] å—
    const block_q4_0* B,    // æƒé‡ [N, K/32] å—
    float* C,               // è¾“å‡º [M, N]
    int M, int N, int K, cudaStream_t stream = 0);

// Level 2: Q8_0 Ã— Q8_1 â†’ FP32
void gemm_q8_0_q8_1(
    const block_q8_1* A,
    const block_q8_0* B,
    float* C,
    int M, int N, int K, cudaStream_t stream = 0);

} // namespace gemm
} // namespace kernels
```

### 3.3 æµ‹è¯•æ¡†æ¶

```cpp
// tests/framework/test_framework.cuh
#pragma once

#include "compat/ggml_types.h"
#include <functional>
#include <string>
#include <vector>

namespace testing {

// è¯¯å·®åº¦é‡
struct ErrorMetrics {
    float mse;
    float nmse;
    float max_err;
    float avg_err;

    void compute(const float* actual, const float* expected, int n);
    bool check(float threshold) const { return nmse < threshold; }
    void print() const;
};

// æµ‹è¯•é…ç½®
struct TestConfig {
    int M = 4, N = 512, K = 1024;
    float threshold = 0.01f;
    unsigned int seed = 42;
    bool verbose = true;
};

// æµ‹è¯•ç”¨ä¾‹åŸºç±»
class TestCase {
public:
    virtual ~TestCase() = default;

    virtual const char* name() const = 0;
    virtual const char* description() const = 0;
    virtual float threshold() const { return 0.01f; }

    virtual void setup(const TestConfig& config) = 0;
    virtual void run_reference() = 0;
    virtual void run_kernel() = 0;
    virtual void cleanup() = 0;

    bool run(const TestConfig& config);

protected:
    ErrorMetrics metrics_;
    float* output_ref_ = nullptr;
    float* output_test_ = nullptr;
    int output_size_ = 0;
};

// æµ‹è¯•è¿è¡Œå™¨
class TestRunner {
public:
    void add(TestCase* test) { tests_.push_back(test); }
    void run_all(const TestConfig& config);
    void print_summary();

private:
    std::vector<TestCase*> tests_;
    std::vector<std::pair<std::string, bool>> results_;
};

} // namespace testing
```

---

## 4. ä¸ llama.cpp çš„å…¼å®¹æ€§

### 4.1 æ¥å£å¯¹é½æ£€æŸ¥æ¸…å•

| ç»„ä»¶ | llama.cpp ä½ç½® | æœ¬é¡¹ç›®ä½ç½® | çŠ¶æ€ |
|------|---------------|-----------|------|
| block_q4_0 | ggml-common.h:174 | compat/ggml_types.h | â¬œ |
| block_q4_1 | ggml-common.h:186 | compat/ggml_types.h | â¬œ |
| block_q8_0 | ggml-common.h:223 | compat/ggml_types.h | â¬œ |
| block_q8_1 | ggml-common.h:236 | compat/ggml_types.h | â¬œ |
| QK4_0 | ggml-common.h:171 | compat/ggml_types.h | â¬œ |
| GEMM æ¥å£ | mmq.cuh | kernels/gemm/ | âœ… |

### 4.2 ç±»å‹åŒæ­¥è„šæœ¬

```python
#!/usr/bin/env python3
# tools/sync_llama_types.py

"""
ä» llama.cpp åŒæ­¥ç±»å‹å®šä¹‰åˆ°æœ¬é¡¹ç›®

ç”¨æ³•:
    python tools/sync_llama_types.py /path/to/llama.cpp
"""

import re
import sys
from pathlib import Path

def extract_types(llama_path: Path):
    """ä» llama.cpp æå–ç±»å‹å®šä¹‰"""
    common_h = llama_path / "ggml" / "src" / "ggml-common.h"

    if not common_h.exists():
        print(f"Error: {common_h} not found")
        sys.exit(1)

    content = common_h.read_text()

    # æå–å—å®šä¹‰
    block_pattern = r'typedef struct \{[^}]+\} (block_q\d+_\d+);'
    blocks = re.findall(block_pattern, content, re.DOTALL)

    # æå–å¸¸é‡å®šä¹‰
    const_pattern = r'#define (QK\d+_\d+) (\d+)'
    constants = re.findall(const_pattern, content)

    return blocks, constants

def generate_header(blocks, constants):
    """ç”Ÿæˆå…¼å®¹å±‚å¤´æ–‡ä»¶"""
    header = '''// compat/ggml_types.h
// Auto-generated from llama.cpp - DO NOT EDIT MANUALLY
// Generated by: tools/sync_llama_types.py

#pragma once

#include <cuda_fp16.h>
#include <cstdint>

// Block size constants
'''
    for name, value in constants:
        header += f'#define {name} {value}\n'

    header += '''
// Quantization block types
// (Types extracted from llama.cpp/ggml/src/ggml-common.h)
'''
    # Add block definitions...

    return header

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python sync_llama_types.py /path/to/llama.cpp")
        sys.exit(1)

    llama_path = Path(sys.argv[1])
    blocks, constants = extract_types(llama_path)
    header = generate_header(blocks, constants)
    print(header)
```

### 4.3 é›†æˆåˆ° llama.cpp çš„æ–¹æ³•

```cpp
// æ–¹æ³• 1: ç›´æ¥åŒ…å«ï¼ˆæ¨èç”¨äºå¼€å‘æµ‹è¯•ï¼‰
// åœ¨ llama.cpp/ggml/src/ggml-cuda/mmq.cuh ä¸­:
#include "/path/to/quant-gemm-from-scratch/kernels/gemm/gemm_dp4a.cuh"

// æ–¹æ³• 2: ç¼–è¯‘ä¸ºåº“å¹¶é“¾æ¥
// CMakeLists.txt:
add_library(custom_kernels STATIC
    kernels/gemm/gemm_dp4a.cu
    kernels/activation/silu.cu
    # ...
)

// æ–¹æ³• 3: å¤´æ–‡ä»¶åº“ï¼ˆheader-onlyï¼‰
// æ‰€æœ‰å®ç°éƒ½åœ¨ .cuh æ–‡ä»¶ä¸­ï¼Œç›´æ¥åŒ…å«å³å¯
```

---

## 5. æµ‹è¯•ç­–ç•¥

### 5.1 æµ‹è¯•å±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æµ‹è¯•é‡‘å­—å¡”                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                    â”‚ é›†æˆæµ‹è¯•      â”‚  â† llama.cpp å…¼å®¹æ€§        â”‚
â”‚                    â”‚ (Integration) â”‚                            â”‚
â”‚                   â”Œâ”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”                           â”‚
â”‚                   â”‚  æ€§èƒ½æµ‹è¯•       â”‚  â† Nsight, nvprof         â”‚
â”‚                   â”‚  (Benchmark)    â”‚                           â”‚
â”‚                  â”Œâ”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”                          â”‚
â”‚                  â”‚    å•å…ƒæµ‹è¯•       â”‚  â† æ¯ä¸ª kernel           â”‚
â”‚                  â”‚    (Unit Tests)   â”‚                          â”‚
â”‚                 â”Œâ”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”                         â”‚
â”‚                 â”‚     æ­£ç¡®æ€§æµ‹è¯•      â”‚  â† ä¸ CPU å‚è€ƒå¯¹æ¯”      â”‚
â”‚                 â”‚  (Correctness)      â”‚                         â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 æµ‹è¯•æ–‡ä»¶å‘½åè§„èŒƒ

```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_gemm_fp32.cu          # å•å…ƒæµ‹è¯•: FP32 GEMM
â”‚   â”œâ”€â”€ test_gemm_q4_0.cu          # å•å…ƒæµ‹è¯•: Q4_0 GEMM
â”‚   â”œâ”€â”€ test_silu.cu               # å•å…ƒæµ‹è¯•: SiLU
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_llama_gemm.cu         # é›†æˆæµ‹è¯•: ä¸ llama.cpp å¯¹æ¯”
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ benchmark/
    â”œâ”€â”€ bench_gemm_sizes.cu        # ä¸åŒçŸ©é˜µå¤§å°çš„æ€§èƒ½
    â””â”€â”€ bench_gemm_vs_cublas.cu    # ä¸ cuBLAS å¯¹æ¯”
```

---

## 6. æ•™ç¨‹åšå®¢ç³»ç»Ÿ

### 6.1 æ•™ç¨‹ç»“æ„æ¨¡æ¿

```markdown
# tutorials/XX-topic-name/README.md

# æ•™ç¨‹ XX: ä¸»é¢˜åç§°

## å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬æ•™ç¨‹åï¼Œä½ å°†èƒ½å¤Ÿï¼š
- [ ] ç›®æ ‡ 1
- [ ] ç›®æ ‡ 2
- [ ] ç›®æ ‡ 3

## å‰ç½®çŸ¥è¯†

- éœ€è¦äº†è§£çš„çŸ¥è¯†ç‚¹ 1
- éœ€è¦äº†è§£çš„çŸ¥è¯†ç‚¹ 2

## ç†è®ºèƒŒæ™¯

### æ¦‚å¿µè§£é‡Š
...

### æ•°å­¦å…¬å¼
$$
C = A \times B
$$

## å®ç°æ­¥éª¤

### Step 1: åŸºç¡€å®ç°
```cuda
// ä»£ç ç¤ºä¾‹
```

### Step 2: ä¼˜åŒ–
...

## å®éªŒä¸éªŒè¯

### è¿è¡Œæµ‹è¯•
```bash
./test_xxx
```

### é¢„æœŸç»“æœ
...

## ç»ƒä¹ é¢˜

1. å°è¯•ä¿®æ”¹ xxx å‚æ•°ï¼Œè§‚å¯Ÿç»“æœå˜åŒ–
2. å®ç° xxx çš„ä¼˜åŒ–ç‰ˆæœ¬

## å‚è€ƒèµ„æ–™

- [é“¾æ¥ 1](url)
- [é“¾æ¥ 2](url)

## ä¸‹ä¸€æ­¥

ç»§ç»­å­¦ä¹  [æ•™ç¨‹ XX+1: ä¸‹ä¸€ä¸»é¢˜](../XX+1-next-topic/)
```

### 6.2 æ•™ç¨‹è·¯çº¿å›¾

```
tutorials/
â”‚
â”œâ”€â”€ 00-introduction/
â”‚   â””â”€â”€ README.md                # é¡¹ç›®ä»‹ç»å’Œç¯å¢ƒé…ç½®
â”‚
â”œâ”€â”€ 01-cuda-basics/
â”‚   â”œâ”€â”€ README.md                # CUDA ç¼–ç¨‹åŸºç¡€
â”‚   â”œâ”€â”€ 01-hello-world.md        # Hello CUDA
â”‚   â”œâ”€â”€ 02-thread-hierarchy.md   # çº¿ç¨‹å±‚æ¬¡ç»“æ„
â”‚   â”œâ”€â”€ 03-memory-model.md       # å†…å­˜æ¨¡å‹
â”‚   â””â”€â”€ code/
â”‚       â”œâ”€â”€ hello.cu
â”‚       â””â”€â”€ vector_add.cu
â”‚
â”œâ”€â”€ 02-gemm-naive/
â”‚   â”œâ”€â”€ README.md                # æœ´ç´  GEMM å®ç°
â”‚   â”œâ”€â”€ 01-cpu-reference.md      # CPU å‚è€ƒå®ç°
â”‚   â”œâ”€â”€ 02-naive-gpu.md          # æœ´ç´  GPU å®ç°
â”‚   â”œâ”€â”€ 03-correctness-check.md  # æ­£ç¡®æ€§éªŒè¯
â”‚   â””â”€â”€ code/
â”‚
â”œâ”€â”€ 03-gemm-tiled/
â”‚   â”œâ”€â”€ README.md                # Tiled GEMM ä¼˜åŒ–
â”‚   â”œâ”€â”€ 01-shared-memory.md      # Shared Memory ä»‹ç»
â”‚   â”œâ”€â”€ 02-tiled-algorithm.md    # åˆ†å—ç®—æ³•
â”‚   â”œâ”€â”€ 03-bank-conflicts.md     # Bank Conflict ä¼˜åŒ–
â”‚   â””â”€â”€ code/
â”‚
â”œâ”€â”€ 04-quantization-basics/
â”‚   â”œâ”€â”€ README.md                # é‡åŒ–åŸºç¡€
â”‚   â”œâ”€â”€ 01-why-quantize.md       # ä¸ºä»€ä¹ˆè¦é‡åŒ–
â”‚   â”œâ”€â”€ 02-symmetric-quant.md    # å¯¹ç§°é‡åŒ–
â”‚   â”œâ”€â”€ 03-asymmetric-quant.md   # éå¯¹ç§°é‡åŒ–
â”‚   â”œâ”€â”€ 04-block-quantization.md # å—é‡åŒ–
â”‚   â””â”€â”€ code/
â”‚
â”œâ”€â”€ 05-q4-gemm/
â”‚   â”œâ”€â”€ README.md                # Q4 GEMM å®ç°
â”‚   â”œâ”€â”€ 01-q4-format.md          # Q4_0 æ ¼å¼è¯¦è§£
â”‚   â”œâ”€â”€ 02-dequant-gemm.md       # åé‡åŒ– GEMM
â”‚   â”œâ”€â”€ 03-compensation.md       # è¡¥å¿å…¬å¼æ¨å¯¼
â”‚   â””â”€â”€ code/
â”‚
â”œâ”€â”€ 06-dp4a-optimization/
â”‚   â”œâ”€â”€ README.md                # DP4A ä¼˜åŒ–
â”‚   â”œâ”€â”€ 01-dp4a-intro.md         # DP4A æŒ‡ä»¤ä»‹ç»
â”‚   â”œâ”€â”€ 02-data-packing.md       # æ•°æ®æ‰“åŒ…
â”‚   â”œâ”€â”€ 03-implementation.md     # å®ç°ç»†èŠ‚
â”‚   â””â”€â”€ code/
â”‚
â”œâ”€â”€ 07-activation-functions/
â”‚   â”œâ”€â”€ README.md                # æ¿€æ´»å‡½æ•°
â”‚   â”œâ”€â”€ 01-silu.md               # SiLU å®ç°
â”‚   â”œâ”€â”€ 02-gelu.md               # GELU å®ç°
â”‚   â””â”€â”€ code/
â”‚
â”œâ”€â”€ 08-normalization/
â”‚   â”œâ”€â”€ README.md                # å½’ä¸€åŒ–å±‚
â”‚   â”œâ”€â”€ 01-rms-norm.md           # RMS Norm
â”‚   â”œâ”€â”€ 02-layer-norm.md         # Layer Norm
â”‚   â””â”€â”€ code/
â”‚
â”œâ”€â”€ 09-attention/
â”‚   â”œâ”€â”€ README.md                # æ³¨æ„åŠ›æœºåˆ¶
â”‚   â”œâ”€â”€ 01-softmax.md            # Softmax
â”‚   â”œâ”€â”€ 02-rope.md               # RoPE
â”‚   â”œâ”€â”€ 03-flash-attention.md    # Flash Attention
â”‚   â””â”€â”€ code/
â”‚
â””â”€â”€ 10-llama-integration/
    â”œâ”€â”€ README.md                # llama.cpp é›†æˆ
    â”œâ”€â”€ 01-interface-analysis.md # æ¥å£åˆ†æ
    â”œâ”€â”€ 02-integration.md        # é›†æˆæ­¥éª¤
    â”œâ”€â”€ 03-testing.md            # æµ‹è¯•éªŒè¯
    â””â”€â”€ code/
```

---

## 7. å¼€å‘æµç¨‹

### 7.1 æ·»åŠ æ–°ç®—å­çš„æ ‡å‡†æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ–°ç®—å­å¼€å‘æµç¨‹                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. ğŸ“– ç ”ç©¶ llama.cpp ä¸­çš„å®ç°                                  â”‚
â”‚     â””â”€â†’ é˜…è¯»æºç ï¼Œç†è§£æ¥å£å’Œç®—æ³•                                â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  2. ğŸ“ è®¾è®¡æ¥å£                                                 â”‚
â”‚     â””â”€â†’ ç¡®ä¿ä¸ llama.cpp å®Œå…¨å…¼å®¹                               â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  3. âœï¸  å®ç° CPU å‚è€ƒç‰ˆæœ¬                                       â”‚
â”‚     â””â”€â†’ ä½œä¸ºæ­£ç¡®æ€§éªŒè¯çš„åŸºå‡†                                    â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  4. ğŸš€ å®ç° GPU Kernel                                          â”‚
â”‚     â””â”€â†’ ä»æœ´ç´ å®ç°å¼€å§‹ï¼Œé€æ­¥ä¼˜åŒ–                                â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  5. ğŸ§ª ç¼–å†™æµ‹è¯•                                                 â”‚
â”‚     â””â”€â†’ å•å…ƒæµ‹è¯• + é›†æˆæµ‹è¯•                                     â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  6. ğŸ“Š æ€§èƒ½æµ‹è¯•                                                 â”‚
â”‚     â””â”€â†’ ä¸ llama.cpp åŸå®ç°å¯¹æ¯”                                 â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  7. ğŸ“š ç¼–å†™æ•™ç¨‹                                                 â”‚
â”‚     â””â”€â†’ è®°å½•å­¦ä¹ è¿‡ç¨‹å’Œå¿ƒå¾—                                      â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  8. ğŸ”— é›†æˆæµ‹è¯•                                                 â”‚
â”‚     â””â”€â†’ æ›¿æ¢ llama.cpp ä¸­çš„ç®—å­ï¼ŒéªŒè¯æ­£ç¡®æ€§                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 ä»£ç è§„èŒƒ

```cpp
/**
 * @file kernels/gemm/gemm_q4_0.cuh
 * @brief Q4_0 é‡åŒ– GEMM å®ç°
 *
 * å®ç° Q4_0 æƒé‡ä¸ Q8_1 æ¿€æ´»çš„çŸ©é˜µä¹˜æ³•
 *
 * ä¸ llama.cpp å…¼å®¹æ€§:
 * - æ¥å£å…¼å®¹: âœ… ä¸ mmq.cuh ä¸­çš„è°ƒç”¨æ–¹å¼ä¸€è‡´
 * - ç±»å‹å…¼å®¹: âœ… ä½¿ç”¨ç›¸åŒçš„ block_q4_0, block_q8_1 ç±»å‹
 * - ç²¾åº¦å…¼å®¹: âœ… NMSE < 1%
 *
 * æ€§èƒ½ç‰¹ç‚¹:
 * - ä½¿ç”¨ DP4A æŒ‡ä»¤åŠ é€Ÿæ•´æ•°ç‚¹ç§¯
 * - ä½¿ç”¨ Shared Memory å‡å°‘å…¨å±€å†…å­˜è®¿é—®
 *
 * @author Your Name
 * @date 2026-01-28
 */

#pragma once

#include "compat/ggml_types.h"

namespace kernels {
namespace gemm {

/**
 * Q4_0 Ã— Q8_1 çŸ©é˜µä¹˜æ³• Kernel
 *
 * è®¡ç®— C = A Ã— Bï¼Œå…¶ä¸­:
 * - A: æ¿€æ´»çŸ©é˜µ [M, K]ï¼ŒQ8_1 é‡åŒ–
 * - B: æƒé‡çŸ©é˜µ [N, K]ï¼ŒQ4_0 é‡åŒ–
 * - C: è¾“å‡ºçŸ©é˜µ [M, N]ï¼ŒFP32
 *
 * è¡¥å¿å…¬å¼:
 *   result = d_w * (d_a * sumi - 8 * s_a)
 *
 * å…¶ä¸­:
 * - d_w: Q4_0 çš„ç¼©æ”¾å› å­
 * - d_a: Q8_1 çš„ç¼©æ”¾å› å­
 * - s_a: Q8_1 çš„åŸå§‹å€¼æ±‚å’Œ
 * - sumi: é‡åŒ–å€¼çš„ç‚¹ç§¯
 *
 * @param A     æ¿€æ´»çŸ©é˜µï¼ŒQ8_1 æ ¼å¼ï¼Œshape [M, K/32] blocks
 * @param B     æƒé‡çŸ©é˜µï¼ŒQ4_0 æ ¼å¼ï¼Œshape [N, K/32] blocks
 * @param C     è¾“å‡ºçŸ©é˜µï¼ŒFP32ï¼Œshape [M, N]
 * @param M     Batch size (è¾“å‡ºè¡Œæ•°)
 * @param N     Output dimension (è¾“å‡ºåˆ—æ•°)
 * @param K     Hidden dimension (å†…éƒ¨ç»´åº¦ï¼Œå¿…é¡»æ˜¯ 32 çš„å€æ•°)
 */
static __global__ void gemm_q4_0_q8_1_kernel(
    const block_q8_1* __restrict__ A,
    const block_q4_0* __restrict__ B,
    float* __restrict__ C,
    int M, int N, int K)
{
    // å®ç°...
}

} // namespace gemm
} // namespace kernels
```

---

## 8. ç®—å­å®ç°è·¯çº¿å›¾

### 8.1 ä¼˜å…ˆçº§æ’åº

| ä¼˜å…ˆçº§ | ç®—å­ | éš¾åº¦ | é¢„è®¡æ—¶é—´ | çŠ¶æ€ |
|--------|------|------|----------|------|
| P0 | GEMM Q4_0 | â­â­â­ | å·²å®Œæˆ | âœ… |
| P1 | SILU | â­ | 1å¤© | âœ… |
| P1 | GELU | â­ | 1å¤© | âœ… |
| P1 | RMS_NORM | â­â­ | 2å¤© | âœ… |
| P1 | ADD | â­ | 0.5å¤© | âœ… |
| P2 | GEMM Q4_1 | â­â­â­ | 3å¤© | â¬œ |
| P2 | GEMM Q8_0 | â­â­ | 2å¤© | â¬œ |
| P2 | MUL | â­ | 0.5å¤© | â¬œ |
| P2 | SCALE | â­ | 0.5å¤© | â¬œ |
| P3 | SOFTMAX | â­â­ | 2å¤© | â¬œ |
| P3 | ROPE | â­â­â­ | 4å¤© | â¬œ |
| P4 | FLASH_ATTN | â­â­â­â­â­ | 2å‘¨ | â¬œ |

### 8.2 å­¦ä¹ æ›²çº¿

```
éš¾åº¦
 ^
 â”‚
5â”‚                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                                        â”‚FLASH   â”‚
 â”‚                                        â”‚ATTN    â”‚
4â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚                          â”‚ROPE    â”‚
 â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
3â”‚            â”‚Q4 GEMM â”‚
 â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
2â”‚    â”‚TILED â”‚              â”‚SOFTMAX â”‚
 â”‚    â”‚GEMM  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
1â”‚    â””â”€â”€â”€â”€â”€â”€â”˜  â”‚RMS_NORMâ”‚
 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚ â”‚NAIVE   â”‚ â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”
0â”‚ â”‚GEMM    â”‚ â”‚SILUâ”‚ â”‚ADD â”‚
 â””â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”´â”€â”€â”€â”€â”´â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ æ—¶é—´
    Week 1    Week 2  Week 3  Week 4  Week 5  Week 6+
```

---

## ğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **é‡æ„å·¥ç¨‹ç›®å½•** - æŒ‰ç…§æœ¬æ–‡æ¡£çš„ç»“æ„é‡æ–°ç»„ç»‡æ–‡ä»¶
2. **åˆ›å»ºå…¼å®¹å±‚** - å®ç° `compat/ggml_types.h`
3. **è¿ç§»ç°æœ‰ä»£ç ** - å°†å·²æœ‰çš„ GEMM å®ç°è¿ç§»åˆ°æ–°ç»“æ„
4. **ç¼–å†™ç¬¬ä¸€ä¸ªæ•™ç¨‹** - ä» CUDA åŸºç¡€å¼€å§‹

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-01-28
