# 从崩溃到完美：一个 CUDA Kernel 的 Debug 之旅

> 面向初学者的实战指南 - 如何一步步解决量化 GEMM Kernel 中的隐藏 Bug

---

## 前言

你写好了一个 CUDA kernel，编译通过了，运行也没报错... 但是结果完全是错的！怎么办？

这篇博客将带你经历一次真实的 debug 之旅。我们会遇到各种奇怪的问题：
- 结果误差巨大（NMSE > 1.0）
- 编译时间超过 30 分钟
- 符号重复定义错误

最重要的是，我会展示**如何思考**，而不是只给出解决方案。

---

## 第一幕：问题的发现

### 背景

我们正在实现一个量化矩阵乘法（GEMM）kernel，使用：
- **Q4_0** 格式存储权重（每个值用 4 bit）
- **Q8_1** 格式存储激活（每个值用 8 bit）
- **DP4A** 指令加速计算（点积指令）

这是在为 llama.cpp 项目开发自定义 kernel。

### 测试开始

```bash
$ bash run_test.sh
```

编译成功了！让我们运行测试...

```
========================================
测试配置: M=1024, N=1024, K=2048
========================================

1. 生成测试数据...
   ✓ 生成了 2097152 个激活值和 2097152 个权重值

2. 量化数据...
   ✓ 激活量化为 Q8_1: 65536 个块
   ✓ 权重量化为 Q4_0: 65536 个块
   ✓ 激活量化误差 (NMSE): 1.41622e-05
   ✓ 权重量化误差 (NMSE): 0.00465502

3. 计算 CPU 参考结果...
   ✓ CPU GEMM 完成

4. 运行 GPU kernel...
   ✓ GPU kernel 完成
   ✓ 执行时间: 14.3076 ms

5. 验证结果...
   NMSE: 1.87041
   ❌ 测试失败！误差过大
```

**NMSE = 1.87**？！正常应该小于 0.0001 才对。

这意味着结果完全是错的。让我们看看具体数值：

```
前 10 个值对比:
Index | CPU参考值 | GPU结果 | 差异
------|-----------|---------|------
    0 |   33.4142 |  4.0505 | 29.3638
    1 |  -21.3900 | -8.4812 | -12.9088
    2 |   -0.6364 | -2.5156 |  1.8792
```

GPU 的结果比 CPU 参考值小了很多。

---

## 第二幕：缩小问题范围

### Debug 策略 #1：从简单开始

当面对一个复杂问题时，**不要试图在大数据集上找问题**！

创建一个最小的测试用例：
- 矩阵大小：1×1
- 只计算一个元素
- 手动验证每一步

### 创建简化测试

```cpp
// 测试一个最简单的场景
const int M = 1;
const int N = 1;
const int K = 32;  // 正好一个 block

// A (Q8_1): d=0.5, s=-8
// qs = [-16, -15, -14, ..., 14, 15]

// B (Q4_0): d=0.25
// qs = [0,1, 1,2, 2,3, 3,4, ...]
```

运行简化测试：

```bash
$ ./test_simple

CPU 参考结果: 141
GPU 结果: 71
差异: 70

❌ 测试失败！
```

**发现：GPU 结果正好是 CPU 的一半！**

这是个重要的线索。为什么是一半？

---

## 第三幕：找到第一个 Bug

### 分析代码

让我们看看 kernel 的核心循环：

```cuda
for (int i = 0; i < 4; i++) {
    int a0 = load_int_b4(block_a.qs, i);
    int a1 = load_int_b4(block_a.qs, i + 4);  // ← 注意这里
    int w_packed = load_int_b2(block_w.qs, i);

    int w_lo = expand_q4_low(w_packed);
    int w_hi = expand_q4_high(w_packed);

    sumi = dp4a(a0, w_lo, sumi);
    sumi = dp4a(a1, w_hi, sumi);
}
```

等等... `load_int_b4(block_a.qs, i + 4)`？

`load_int_b4` 的参数是 **int32 的索引**，不是字节索引！

所以：
- `i=0`: 加载第 0 个 int32（字节 0-3）
- `i=1`: 加载第 1 个 int32（字节 4-7）
- `i=0, i+4=4`: 加载第 4 个 int32（字节 16-19）❌

**问题找到了！** 当 `i=0` 时：
- `a0` 加载元素 0-3 ✓
- `a1` 应该加载元素 4-7，但实际加载了元素 16-19 ❌

### 修复

```cuda
for (int i = 0; i < 4; i++) {
    int a0 = load_int_b4(block_a.qs, i * 2);      // 加载 [i*8 : i*8+3]
    int a1 = load_int_b4(block_a.qs, i * 2 + 1);  // 加载 [i*8+4 : i*8+7]
    // ...
}
```

### 验证修复

```bash
$ ./test_simple

CPU 参考结果: 141
GPU 结果: 139
差异: 2

❌ 测试失败！
```

好多了！从 70 的差异降到 2。但还不对...

---

## 第四幕：深入理解数据格式

### 问题：还有 2 的差异

让我们手动计算一下，看看谁是对的。

#### 量化格式回顾

**Q4_0 格式**（4-bit 量化）：
```cpp
struct block_q4_0 {
    half d;              // scale
    uint8_t qs[16];      // 16 字节，每字节存 2 个 4-bit 值
};
```

存储方式：`(high << 4) | low`
- 字节 0: `(w1 << 4) | w0`
- 字节 1: `(w3 << 4) | w2`
- ...

**Q8_1 格式**（8-bit 量化）：
```cpp
struct block_q8_1 {
    half2 ds;     // (scale, sum) 打包
    int8_t qs[32]; // 32 个 8-bit 值
};
```

#### 手动计算

让我们用 Python 验证：

```python
# A (Q8_1): d_a=0.5, s_a=-8
q_a = [-16, -15, -14, ..., 14, 15]

# B (Q4_0): d_b=0.25
q_b = [0, 1, 1, 2, 2, 3, 3, 4, ...]

# 计算量化值的点积
sumi = sum(q_a[i] * q_b[i] for i in range(32))
# sumi = 1000

# 应用补偿公式
result = d_b * (d_a * sumi - 8 * s_a)
#       = 0.25 * (0.5 * 1000 - 8 * (-8))
#       = 0.25 * (500 + 64)
#       = 0.25 * 564
#       = 141
```

**CPU 的 141 是正确的！** GPU 算出了 139，差了 2。

---

## 第五幕：理解 Nibble 展开的问题

### 问题：数据交错方式不对

让我们详细看看 GPU 是如何计算的。

#### 当前的展开方式

```cuda
int expand_q4_low(int packed) {
    return (packed >> 0) & 0x0F0F0F0F;  // 提取每个字节的低 4 位
}

int expand_q4_high(int packed) {
    return (packed >> 4) & 0x0F0F0F0F;  // 提取每个字节的高 4 位
}
```

假设我们有 4 个字节的 Q4_0 数据：
```
字节 0: (w1 << 4) | w0
字节 1: (w3 << 4) | w2
字节 2: (w5 << 4) | w4
字节 3: (w7 << 4) | w6
```

展开后：
```
w_lo = [w0, w2, w4, w6]  // 所有字节的低位
w_hi = [w1, w3, w5, w7]  // 所有字节的高位
```

#### GPU 的计算过程

```cuda
// i=0:
a0 = [a0, a1, a2, a3]     // 元素 0-3
a1 = [a4, a5, a6, a7]     // 元素 4-7

sumi += a0*w0 + a1*w2 + a2*w4 + a3*w6   // DP4A(a0, w_lo)
sumi += a4*w1 + a5*w3 + a6*w5 + a7*w7   // DP4A(a1, w_hi)
```

**问题：元素和权重对应不上！**

正确应该是：
```
sumi += a0*w0 + a1*w1 + a2*w2 + a3*w3
sumi += a4*w4 + a5*w5 + a6*w6 + a7*w7
```

### 解决方案：交错展开

我们需要重新排列权重：

```cuda
void expand_q4_interleaved(int packed, int& out0, int& out1) {
    // 输入: 4 字节包含 8 个 4-bit 值
    int lo = (packed >> 0) & 0x0F0F0F0F;  // [w0, w2, w4, w6]
    int hi = (packed >> 4) & 0x0F0F0F0F;  // [w1, w3, w5, w7]

    // 输出:
    // out0 = [w0, w1, w2, w3]  // 与 a[0-3] 对应
    // out1 = [w4, w5, w6, w7]  // 与 a[4-7] 对应

    out0 = ((lo & 0x000000FF) <<  0) |  // w0 → 字节 0
           ((hi & 0x000000FF) <<  8) |  // w1 → 字节 1
           ((lo & 0x0000FF00) <<  8) |  // w2 → 字节 2
           ((hi & 0x0000FF00) << 16);   // w3 → 字节 3

    out1 = ((lo & 0x00FF0000) >> 16) |  // w4 → 字节 0
           ((hi & 0x00FF0000) >>  8) |  // w5 → 字节 1
           ((lo & 0xFF000000) >>  8) |  // w6 → 字节 2
           ((hi & 0xFF000000) >>  0);   // w7 → 字节 3
}
```

### 图示理解

```
原始布局（内存中）:
┌────────┬────────┬────────┬────────┐
│ 字节 0 │ 字节 1 │ 字节 2 │ 字节 3 │
└────────┴────────┴────────┴────────┘
│w1│w0  │w3│w2  │w5│w4  │w7│w6  │
└──┴──┘ └──┴──┘ └──┴──┘ └──┴──┘

展开后（用于 DP4A）:
out0: ┌───┬───┬───┬───┐     out1: ┌───┬───┬───┬───┐
      │ w0│ w1│ w2│ w3│           │ w4│ w5│ w6│ w7│
      └───┴───┴───┴───┘           └───┴───┴───┴───┘
      与 a[0-3] 配对               与 a[4-7] 配对
```

### 验证修复

```bash
$ ./test_simple

CPU 参考结果: 141
GPU 结果: 141
差异: 0

✅ 测试通过！
```

完美！现在运行完整测试：

```bash
$ bash run_test.sh

========================================
测试配置: M=1024, N=1024, K=2048
========================================

5. 验证结果...
   NMSE: 5.38e-05
   ✅ 测试通过！结果正确
```

---

## 第六幕：额外的问题（编译相关）

虽然 kernel 现在正确了，但我们在 debug 过程中还遇到了其他问题。

### 问题 1：编译时间过长

**现象**: 编译需要 32+ 分钟

**原因**: llama.cpp 默认为 13 个不同的 GPU 架构编译
```
sm_50, sm_52, sm_60, sm_61, sm_70, sm_75,
sm_80, sm_86, sm_89, sm_90, sm_100, sm_101, sm_120a
```

每个 .cu 文件都要编译 13 次！

**解决**: 只编译你的 GPU 架构
```bash
cmake .. -DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES="120a"
```

编译时间降至 ~3 分钟！

### 问题 2：符号重复定义

**现象**: 链接时报错
```
multiple definition of `gemm_w4a8_dp4a_kernel'
```

**原因**: Kernel 函数在头文件中定义，被多个 .cu 文件包含

**解决**: 声明为 `static`
```cuda
static __global__ void gemm_w4a8_dp4a_kernel(...)
```

---

## Debug 经验总结

### 1. 从最小测试开始

❌ **错误做法**: 在 1024×1024 的大矩阵上找问题
✅ **正确做法**: 先测试 1×1 的单个元素

### 2. 验证假设

不要相信任何假设，都要验证：
- 数据格式理解对了吗？
- 内存布局是预期的吗？
- 索引计算正确吗？

### 3. 手动计算

当你不确定时，用 Python 或计算器手动算一遍：
```python
# 用几行代码验证逻辑
result = sum(a[i] * b[i] for i in range(32))
```

### 4. 画图理解

对于复杂的数据布局，画图最清晰：
```
内存: [w1|w0][w3|w2][w5|w4][w7|w6]
           ↓
展开:  [w0][w1][w2][w3] | [w4][w5][w6][w7]
```

### 5. 一次只改一个地方

当你改了代码后，立即测试。不要一次性改 10 个地方。

---

## 给初学者的建议

### CUDA Debug 工具箱

1. **简化测试**
   - 小数据量
   - 可预测的输入
   - 容易手算的结果

2. **打印中间结果**
   ```cuda
   printf("blockIdx=(%d,%d) threadIdx=(%d,%d) sum=%f\n",
          blockIdx.x, blockIdx.y, threadIdx.x, threadIdx.y, sum);
   ```

3. **使用 CUDA-MEMCHECK**
   ```bash
   cuda-memcheck ./your_program
   ```

4. **Nsight Compute**
   - 查看详细的 kernel 性能
   - 分析内存访问模式

### 常见陷阱

1. **索引错误**: 最常见！
   - 混淆字节索引和元素索引
   - 忘记 stride
   - 边界条件

2. **数据对齐**
   - 2 字节对齐 vs 4 字节对齐
   - 使用 `load_int_b2` vs `load_int_b4`

3. **位操作**
   - 符号扩展
   - 移位方向
   - 掩码操作

4. **同步问题**
   - 忘记 `cudaDeviceSynchronize()`
   - 共享内存的 `__syncthreads()`

---

## 结语

这个 bug 花了我们几个小时才找到，但这是一个很有价值的学习过程：

1. **不要慌**: 结果不对不代表代码全错了
2. **系统化**: 从简单到复杂，一步步验证
3. **理解深入**: 真正理解数据格式是关键
4. **工具很重要**: Python 验证、图示、简化测试

最重要的是：**Debug 是一个思考的过程，不是试错的过程**。

每一次 bug 都是深入理解系统的好机会。好好享受这个过程吧！

---

## 附录：完整代码

最终的交错展开函数：

```cuda
__device__ __forceinline__ void expand_q4_interleaved(
    int packed, int& out0, int& out1) {

    int lo = (packed >> 0) & 0x0F0F0F0F;  // [w0, w2, w4, w6]
    int hi = (packed >> 4) & 0x0F0F0F0F;  // [w1, w3, w5, w7]

    // 重新交错以匹配激活值顺序
    out0 = ((lo & 0x000000FF) <<  0) |
           ((hi & 0x000000FF) <<  8) |
           ((lo & 0x0000FF00) <<  8) |
           ((hi & 0x0000FF00) << 16);

    out1 = ((lo & 0x00FF0000) >> 16) |
           ((hi & 0x00FF0000) >>  8) |
           ((lo & 0xFF000000) >>  8) |
           ((hi & 0xFF000000) >>  0);
}
```

---

*作者: Claude Code*
*日期: 2026-01-28*
*GPU: NVIDIA GeForce RTX 5070 Laptop*

> "Debugging is like being a detective in a crime movie where you are also the murderer." - Someone Wise
